{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAT 202 - Peer Lesson\n",
    "Kayla Bracall\n",
    "September 29, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data cleaning? \n",
    "\n",
    "Data cleaning is \"detecting and removing errors and inconsistencies from data in order to improve the quality of data.\" (Rahm and Do, 2000). Data cleaning can include transforming, translating, integrating and aggregating data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some examples of \"unclean\" data?\n",
    "\n",
    "Unlcean data is data that includes: \n",
    "* spelling errors\n",
    "* missing information\n",
    "* irrelevant data \n",
    "* redundant data\n",
    "* multiple naming conventions for the same data type\n",
    "* data in multpile formats\n",
    "\n",
    "Some causes of unclean data can include human error and different record retention standards across multiple data sources. For example, one dataset may store phone numbers in the format 412-329-0000 while another may store as +1 (412) 329-0000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is data cleaning important?\n",
    "__________\n",
    "\n",
    "Incorrect/unclean data will produce incorrect conclusions. There is truth to the saying \"garbage in, garbage out.\" If data is being used for decision making, it is imperative that this data is as accurate as possible to avoid misleading statistics and inaccurate conclusions. \"Unreliable or misleading results are probably obtained by analyzing poor-quality data.\" (Xu et al, 2020)\n",
    "\n",
    "The concept of clean becomes especially important when working with Big Data or using data to make decisions that will affect the lives of others. \n",
    "\n",
    "Unclean data can exist even in a single dataset, but when combining datasets, data cleaning becomes even more important.\n",
    "\n",
    "Let's look at a rudimentary example: https://github.com/kaylabracall/dat-202/blob/master/peer_lesson.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data cleaning process:\n",
    "____________\n",
    "\n",
    "In their book _Problems, Methods and Challenges in Comprehensive Data Cleansing,_ authors Heiko Müller and Johann-Christoph Freytag propose the below process for data cleansing. \n",
    "\n",
    "#### Data Auditing\n",
    "The first step in data cleansing is \"auditing the data to find the types of anomalies contained within it.\" In short, the user needs to know what kind of errors the data contains. \n",
    "####  Workflow Specification\n",
    "The next step is to detect and remove annomalies in the data. Muller and Freytag call this \"Workflow Specification.\" If the source of an error is known, it may be possible to correct the error. This step can also help identify systematic errors in data collection. \n",
    "#### Workflow Execution\n",
    "Next, the data cleansing process is executed. Depending on the size of the dataset, this can be a time and resource intensive process.\n",
    "#### Post Processing\n",
    "Once the cleansing is complete, it should be verified for accuracy, and the process can begin again, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some methods of data cleaning?\n",
    "_______________\n",
    "\n",
    "#### Parsing\n",
    "Parsing serves the purpose of detecting syntax errors. \n",
    "#### Data Transformation\n",
    "Data is transformed to ensure all data is in the same format \n",
    "#### Integrity Constraint Enforcement\n",
    "\"Integrity constraint enforcement ensures the satisfaction of integrity constraints after transactions modifying a data collection. [...] have occured\" (Müller and Freytag, 2005)\n",
    "* Integrity constraint checking - removes data that does not meet an integrity constraint\n",
    "* Integrity constraint maintenance - identifies repairs that can be added so that the data does not violate an integrity constraint \n",
    "\n",
    "#### Duplicate Elimination \n",
    "The removal of duplicate data. An algorithm should be used to determine whether an datapoint is a duplicate to one that already exits in the dataset\n",
    "\n",
    "#### Statistical Methods\n",
    "Statistical analyses on the data can be performed to identify outliers or possibly invalid data. This data can then be reviewed in more detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Tools\n",
    "________\n",
    "Some popular data cleaning tools inclulde:\n",
    "* Open Refine\n",
    "* Tableau\n",
    "* DataWrangler\n",
    "* _Python and R!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unclean Data in the Real World - A Personal Example:\n",
    "__________\n",
    "\n",
    "For my final project in ATE 252, I analyzed crash fatality data for drivers aged 65 and older. The crash data was provided by PennDot and included data from years 1997 - 2018. Here are some of the obstacles I ran into with the data:\n",
    "\n",
    "1. Irrelevant data in the dataset\n",
    "2. Categorical data that I needed to use for statistical analysis \n",
    "2. Null values in some of the datapoints I was analyzing\n",
    "3. _An entire year of missing data_\n",
    "\n",
    "Let's take a look at my solutions: https://github.com/kaylabracall/ate-252/tree/master/FinalProject\n",
    "\n",
    "### Do you agree with my solutions to unclean data? \n",
    "\n",
    "### Do you have any other suggestions with how I could have handled the missing year of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework!\n",
    "Two Readings:\n",
    "\n",
    "Read about executing data cleaning in sections 5 and 6 of _Problems, Methods and Challenges in Comprehensive Data Cleansing:_ http://www.dbis.informatik.hu-berlin.de/fileadmin/research/papers/techreports/2003-hub_ib_164-mueller.pdf\n",
    "\n",
    "Read about one of the most famous examples of the conseuqences of not cleaning/reviewing data: https://www.sciencemag.org/news/1999/09/english-metric-miscue-doomed-mars-mission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations\n",
    "* Friedland, D. (n.d.). A Fresh Look at Data Preparation [Web log post]. Retrieved September 24, 2020, from https://www.iri.com/blog/business-intelligence/a-fresh-look-at-data-preparation/\n",
    "\n",
    "* Müller, H., &amp; Freytag, J. C. (2005). Problems, methods, and challenges in comprehensive data cleansing. Berlin: Professoren des Inst. Für Informatik.\n",
    "\n",
    "* Sukhadeve, A. (2016, December 16). Why data preparation should not be overlooked [Web log post]. Retrieved September 27, 2020, from https://www.datasciencecentral.com/profiles/blogs/why-data-preparation-should-not-be-overlooked#:~:text=The%20importance%20of%20data%20preparation&amp;text=It%20is%20one%20of%20the,the%20accuracy%20of%20the%20outcome.\n",
    "\n",
    "* Xu, X., Lei, Y., &amp; Li, Z. (2020). An Incorrect Data Detection Method for Big Data Cleaning of Machinery Condition Monitoring. IEEE Transactions on Industrial Electronics, 67(3), 2326-2336. doi:10.1109/tie.2019.2903774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
